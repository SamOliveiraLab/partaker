{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Shifting the image by a margin of pixels\n",
    "import skimage.transform as trans\n",
    "from scipy import signal\n",
    "from PIL import Image\n",
    "from scipy import stats as stat\n",
    "from itertools import product\n",
    "\n",
    "# Image Analysis\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from tifffile import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io, exposure, data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import stats as st\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from numpy import diff\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage.filters import unsharp_mask\n",
    "# from wand.image import Image as ImageWand\n",
    "from numpy.polynomial import polynomial as P\n",
    "import cv2\n",
    "from PIL import Image"
   ],
   "id": "412964caef6097d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def save_video(filename, frames):\n",
    "    # frames_rgb: (N, H, W, 3) uint8 in RGB\n",
    "    h, w = frames.shape[1], frames.shape[2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(filename, fourcc, 15.0, (w, h), isColor=True)\n",
    "\n",
    "    for fr in frames:\n",
    "        fr_bgr = cv2.cvtColor(fr, cv2.COLOR_GRAY2BGR)\n",
    "        out.write(fr_bgr)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Saved {filename}\")"
   ],
   "id": "7f38422e99844ec2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Registration 1",
   "id": "1a2523997d8ea07b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dirty Implementation of Shifting Images\n",
    "def ShiftedImage_2D(Image, XShift, YShift):\n",
    "    # Quick guard\n",
    "    if (XShift == 0 and YShift == 0):\n",
    "        return Image;\n",
    "\n",
    "    M = np.float32([\n",
    "    [1, 0, XShift],\n",
    "    [0, 1, YShift]\n",
    "    ]);\n",
    "\n",
    "    shifted = cv2.warpAffine(Image, M, (Image.shape[1], Image.shape[0]));\n",
    "    shifted_image = shifted\n",
    "\n",
    "    # Shift Down\n",
    "    if (YShift > 0):\n",
    "        shifted_image = shifted_image[YShift:];\n",
    "        shifted_image = np.pad(shifted_image, ((YShift, 0), (0, 0)), 'edge'); # Pad Up\n",
    "\n",
    "    # Shift Up\n",
    "    if (YShift < 0):\n",
    "        shifted_image = shifted_image[:shifted.shape[0] - abs(YShift)];\n",
    "        shifted_image = np.pad(shifted_image, ((0, abs(YShift)), (0, 0)), 'edge'); # Pad Down\n",
    "\n",
    "    # Shift Left\n",
    "    if (XShift > 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(0, XShift), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (XShift, 0)), 'edge'); # Pad Left\n",
    "\n",
    "    if (XShift < 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(shifted.shape[1] - abs(XShift), shifted.shape[1]), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (0, abs(XShift))), 'edge'); # Pad Right\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "def ShiftedImage_3D(Image, XShift, YShift):\n",
    "    # Quick guard\n",
    "    if (XShift == 0 and YShift == 0):\n",
    "        return Image;\n",
    "\n",
    "    M = np.float32([\n",
    "    [1, 0, XShift],\n",
    "    [0, 1, YShift]\n",
    "    ]);\n",
    "\n",
    "    shifted = cv2.warpAffine(Image, M, (Image.shape[1], Image.shape[0]));\n",
    "    shifted_image = shifted\n",
    "\n",
    "    # Shift Down\n",
    "    if (YShift > 0):\n",
    "        shifted_image = shifted_image[YShift:];\n",
    "        shifted_image = np.pad(shifted_image, ((YShift, 0), (0, 0), (0, 0)), 'constant', constant_values=(0,)); # Pad Up\n",
    "\n",
    "    # Shift Up\n",
    "    if (YShift < 0):\n",
    "        shifted_image = shifted_image[:shifted.shape[0] - abs(YShift)];\n",
    "        shifted_image = np.pad(shifted_image, ((0, abs(YShift)), (0, 0), (0, 0)), 'constant', constant_values=(0,)); # Pad Down\n",
    "\n",
    "    # Shift Left\n",
    "    if (XShift > 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(0, XShift), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (XShift, 0), (0, 0)), 'constant', constant_values=(0,)); # Pad Left\n",
    "\n",
    "    # Shift Up\n",
    "    if (XShift < 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(shifted.shape[1] - abs(XShift), shifted.shape[1]), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (0, abs(XShift)), (0, 0)), 'constant', constant_values=(0,)); # Pad Right\n",
    "\n",
    "    plt.imshow(shifted_image)\n",
    "    plt.show()\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "def SAD(A,B):\n",
    "    cutA = A.ravel();\n",
    "    cutB = B.ravel();\n",
    "    MAE = np.sum(np.abs(np.subtract(cutA,cutB,dtype=np.float64))) / cutA.shape[0]\n",
    "    return MAE\n",
    "\n",
    "# sum of absolute differences (SAD) metric alignment, quick n dirty\n",
    "# We use a Tree Search Algorithm to find possible alignment\n",
    "# Let Image_1 be the orginal\n",
    "# Let Image_2 be the aligned\n",
    "# Displacement object is our nodes, [x,y]\n",
    "# Assumption, there is always a better alignment up, down, left, and right if its not the same image\n",
    "def alignment_MAE(Image_1, Image_2, depth_cap):\n",
    "    iterative_cap = 0;\n",
    "    Best_SAD = SAD(Image_1, Image_2);\n",
    "    Best_Displacement = [0,0];\n",
    "    q = [];\n",
    "    visited_states = [[0,0]];  # Add (0,0) displacement\n",
    "    q.append(Best_Displacement); # Append (0,0) displacement\n",
    "\n",
    "    while (iterative_cap != depth_cap and q):\n",
    "        curr_state = q.pop(0);\n",
    "        x = curr_state[0];\n",
    "        y = curr_state[1];\n",
    "\n",
    "        iterative_cap += 1;\n",
    "\n",
    "        movement_arr = [\n",
    "            [x, y - 1], # Up\n",
    "            [x, y + 1], # Down\n",
    "            [x + 1, y], # Left\n",
    "            [x - 1, y], # Right\n",
    "            [x - 1, y - 1], # Diagonal\n",
    "            [x + 1, y + 1], # Diagonal\n",
    "            [x + 1, y - 1], # Diagonal\n",
    "            [x - 1, y + 1], # Diagonal\n",
    "        ]\n",
    "\n",
    "        for move in movement_arr:\n",
    "            if (move not in visited_states):\n",
    "                visited_states.append(move); # Marked as Visited\n",
    "\n",
    "                # Perform shift and calculate\n",
    "                new_image = ShiftedImage_2D(Image_2, move[0], move[1]);\n",
    "                cand_SAD = SAD(Image_1, new_image);\n",
    "\n",
    "                if (cand_SAD < Best_SAD):\n",
    "                    Best_SAD = cand_SAD;\n",
    "                    Best_Displacement = move;\n",
    "\n",
    "                    q.append(move);\n",
    "\n",
    "                # This means we cannot find a better move.\n",
    "\n",
    "\n",
    "    return Best_Displacement, Best_SAD\n",
    "\n",
    "# Vec4f is (x1, y1, x2, y2)\n",
    "def y_shift_emphasis(image, block_threshold, MAE_shift):\n",
    "    output_img = image;\n",
    "\n",
    "    # Need to turn into uint8 for Straight Line Detection\n",
    "    img = np.uint8(image);\n",
    "    lsd = cv2.createLineSegmentDetector(0);\n",
    "    lines_contour = lsd.detect(img)[0];\n",
    "\n",
    "    drawn_img = lsd.drawSegments(img,lines_contour);\n",
    "#     plt.imshow(drawn_img)\n",
    "#     plt.show()\n",
    "\n",
    "    horizontal_lines = {};\n",
    "    for x in lines_contour:\n",
    "        for y in x:\n",
    "            cand_gradient = abs(y[1] - y[3]);\n",
    "            if (cand_gradient < 10):\n",
    "                horizontal_lines[cand_gradient] = y;\n",
    "\n",
    "    horz = list(horizontal_lines.values())\n",
    "\n",
    "    top_y = np.min(horz);\n",
    "    bottom_y = np.max(horz);\n",
    "\n",
    "    return top_y, bottom_y\n",
    "\n",
    "# Takes in image and returns the edges for top and bottom parametrically, (x,y)\n",
    "# Takes in RGB image\n",
    "def edge_cropping_estimation_vertical(img, m):\n",
    "    main_bright = img;\n",
    "\n",
    "    local_vertical = [];\n",
    "\n",
    "    # Vertical Cutting\n",
    "    for row in range(0, main_bright.shape[0]):\n",
    "        temp_arr = [];\n",
    "        for col in range(0, main_bright.shape[1]):\n",
    "            temp_arr.append(np.mean(main_bright[row][col]));\n",
    "        local_vertical.append(np.mean(temp_arr));\n",
    "\n",
    "    # ================ Vertical axis squish ================\n",
    "    x_vertical = list(range(1, main_bright.shape[0] + 1 ));\n",
    "    y_vertical = local_vertical;\n",
    "\n",
    "    dydx_vertical = diff(y_vertical)/diff(x_vertical);\n",
    "    y_verticle_dydx = list(range(1, main_bright.shape[0]));\n",
    "\n",
    "    for i in range(0, len(dydx_vertical)):\n",
    "        # Below Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i <= 100) or (dydx_vertical[i] <= -150 and i <= 100)):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "        # Above Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i >= (main_bright.shape[0] - 100)) or (dydx_vertical[i] <= -150 and (main_bright.shape[0] - 100))):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "    top_m_derivatives_ind = np.argpartition(dydx_vertical, m)[m:];\n",
    "    sorted_ind_m = sorted(top_m_derivatives_ind);\n",
    "    clustered_sorted_ind_m = [];\n",
    "\n",
    "    cluster_iter_m = 0;\n",
    "    prev_m = sorted_ind_m[0];\n",
    "    cluster_sum_m = 0;\n",
    "\n",
    "    for i in range(0, len(sorted_ind_m)):\n",
    "        if (i == len(sorted_ind_m) - 1):\n",
    "            clustered_sorted_ind_m.append(int(cluster_sum_m / cluster_iter_m));\n",
    "        # If the previous value is outside the range of the current value, i\n",
    "        elif (prev_m >= (sorted_ind_m[i] + 100) or prev_m <= (sorted_ind_m[i] - 100)):\n",
    "            clustered_sorted_ind_m.append(int(cluster_sum_m / cluster_iter_m));\n",
    "            cluster_sum_m = sorted_ind_m[i];\n",
    "            cluster_iter_m = 1;\n",
    "            prev_m = sorted_ind_m[i];\n",
    "        else:\n",
    "            cluster_sum_m += sorted_ind_m[i];\n",
    "            cluster_iter_m += 1;\n",
    "            prev_m = sorted_ind_m[i];\n",
    "\n",
    "\n",
    "    print(\"The VERTICAL DERIVATIVE:\")\n",
    "    plt.plot(y_verticle_dydx, dydx_vertical);\n",
    "    for i in clustered_sorted_ind_m:\n",
    "        plt.axvline(x = i, color = 'r');\n",
    "    plt.show();\n",
    "\n",
    "    top = clustered_sorted_ind_m[0];\n",
    "    bottom = clustered_sorted_ind_m[len(clustered_sorted_ind_m) - 1];\n",
    "\n",
    "    return top, bottom;\n",
    "\n",
    "# Takes in image and returns the edges for top and bottom parametrically, (x,y)\n",
    "# Assumes Bottom is always min and top is always max\n",
    "def edge_cropping_estimation_vertical_high_low_distr(img):\n",
    "    main_bright = img;\n",
    "\n",
    "    local_vertical = [];\n",
    "\n",
    "    # Vertical Cutting\n",
    "    for row in range(0, main_bright.shape[0]):\n",
    "        temp_arr = [];\n",
    "        for col in range(0, main_bright.shape[1]):\n",
    "            temp_arr.append(np.mean(main_bright[row][col]));\n",
    "        local_vertical.append(np.mean(temp_arr));\n",
    "\n",
    "    # ================ Vertical axis squish ================\n",
    "    x_vertical = list(range(1, main_bright.shape[0] + 1 ));\n",
    "    y_vertical = local_vertical;\n",
    "\n",
    "    dydx_vertical = diff(y_vertical)/diff(x_vertical);\n",
    "    y_verticle_dydx = list(range(1, main_bright.shape[0]));\n",
    "\n",
    "    for i in range(0, len(dydx_vertical)):\n",
    "        # Below Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i <= 100) or (dydx_vertical[i] <= -150 and i <= 100)):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "        # Above Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i >= (main_bright.shape[0] - 100)) or (dydx_vertical[i] <= -150 and (main_bright.shape[0] - 100))):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "    max_val = np.max(dydx_vertical)\n",
    "    max_index = np.where(dydx_vertical == max_val)[0][0];\n",
    "    while(max_index > (img.shape[1]/2)):\n",
    "        print(\"Cycling max_index:\", max_index)\n",
    "        dydx_vertical[max_index] = 0; # Reset the value as it is not needed anymore\n",
    "        max_val = np.max(dydx_vertical)\n",
    "        max_index = np.where(dydx_vertical == max_val)[0][0];\n",
    "\n",
    "    min_val = np.min(dydx_vertical)\n",
    "    min_index = np.where(dydx_vertical == min_val)[0][0];\n",
    "    while(min_index < (img.shape[1]/2)):\n",
    "        print(\"Cycling min_index:\", min_index)\n",
    "        dydx_vertical[min_index] = 0; # Reset the value as it is not needed anymore\n",
    "        min_val = np.min(dydx_vertical)\n",
    "        min_index = np.where(dydx_vertical == min_val)[0][0];\n",
    "\n",
    "    print(\"The VERTICAL DERIVATIVE (Pattern Distribution):\")\n",
    "    plt.plot(y_verticle_dydx, dydx_vertical);\n",
    "    plt.axvline(x = max_index, color = 'r');\n",
    "    plt.axvline(x = min_index, color = 'r');\n",
    "    plt.show();\n",
    "\n",
    "    top = max_index\n",
    "    bottom = min_index\n",
    "\n",
    "    return top, bottom;\n",
    "\n",
    "def remove_stage_jitter_MAE(img_array, iteration_depth : int = 1000, m = False, verbose : bool = False, mcm : bool = False):\n",
    "    # Add Scores path just for curiosity\n",
    "    scores = []\n",
    "    X_shifts = []\n",
    "    Y_shifts = []\n",
    "    shifted_images = []\n",
    "\n",
    "    if img_array.ndim != 3:\n",
    "        print(\"Give a series of grayscale images. Shape: {}\".format(img_array.shape))\n",
    "\n",
    "    base = exposure.rescale_intensity(img_array[0])\n",
    "\n",
    "    base_top, base_bottom = edge_cropping_estimation_vertical_high_low_distr(base)\n",
    "    #     base_top, base_bottom = edge_cropping_estimation_vertical(base, m);\n",
    "\n",
    "    # TODO: verify\n",
    "    if base.ndim == 3:\n",
    "        base = base[:, :, 0] # Reduce to the 2D\n",
    "\n",
    "    iteration = 0 # TODO: implement in more pythonic way\n",
    "\n",
    "    for _frame in img_array[1:]:\n",
    "        iteration += 1\n",
    "\n",
    "        template_image = exposure.rescale_intensity(_frame) # Get rid of low exposure\n",
    "\n",
    "        template_top, template_bottom = edge_cropping_estimation_vertical_high_low_distr(template_image)\n",
    "\n",
    "        if template_image.ndim == 3:\n",
    "            template_image = template_image[:, :, 0] # Reduce to the 2D\n",
    "\n",
    "        displacement, score = alignment_MAE(base, template_image, iteration_depth)\n",
    "        scores.append(score)\n",
    "        print(\"SCORE:\", score)\n",
    "\n",
    "        if mcm:\n",
    "            displacement[0] = 0\n",
    "\n",
    "        X_shifts.append(displacement[0])\n",
    "        Y_shifts.append(int(np.mean([(base_top - template_top), (base_bottom -  template_bottom)])))\n",
    "        shifted_image = ShiftedImage_2D(template_image, displacement[0], int(np.mean([(base_top - template_top), (base_bottom -  template_bottom)]))) # X,Y\n",
    "        shifted_images.append(shifted_image)\n",
    "\n",
    "        # For my purposes\n",
    "        # background = Image.fromarray(base)\n",
    "        # overlay = Image.fromarray(shifted_image)\n",
    "        #\n",
    "        # new_img = Image.blend(background, overlay, 0.5)\n",
    "\n",
    "        # print(\"Overlay for image to compare against jitter (PHC)\", iteration, \":\", filename)\n",
    "        # plt.imshow(new_img)\n",
    "        # plt.show()\n",
    "        #\n",
    "        # # Write the new image in target folder\n",
    "        # cv2.imwrite(os.path.join(output_path, filename), shifted_image);\n",
    "\n",
    "    print (\"Scores:\", scores)\n",
    "    print(\"The X_Shifts:\", X_shifts)\n",
    "    print(\"The Y_Shifts:\", Y_shifts)\n",
    "\n",
    "    return shifted_images, scores"
   ],
   "id": "3169b80090529741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test registration 1\n",
    "import nd2\n",
    "\n",
    "test_dataset = nd2.imread(\n",
    "    '/Users/hiram/Documents/EVERYTHING/20-29 Research/22 OliveiraLab/22.12 ND2 analyzer/nd2-analyzer/SR_1_5_2h_Pre-C_3h_IPTG_After10h_05_MC.nd2',\n",
    "    dask=True)\n",
    "test_pos_over_time = test_dataset[:, 0, 0].compute()\n",
    "\n",
    "# Normalization\n",
    "norm = cv2.normalize(test_pos_over_time, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "plt.imshow(norm[0], cmap='gray')\n",
    "plt.show()\n",
    "# frames: (N,H,W) uint8\n",
    "frames = ((norm / 65535) * 255).astype(np.uint8)\n",
    "frames_rgb = np.stack([frames] * 3, axis=-1)  # (N,H,W,3)\n",
    "aligned, scores = remove_stage_jitter_MAE(frames)\n",
    "\n",
    "# Save both timelapses and evaluate\n",
    "save_video(\"original_1.mp4\", frames)\n",
    "save_video(\"registered_1.mp4\", np.array(aligned))"
   ],
   "id": "eec0c69f3acdddc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c6488f56fdf89eb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Registration 2",
   "id": "597a6e7ae2c7efe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dirty Implementation of Shifting Images\n",
    "def ShiftedImage_2D(Image, XShift, YShift):\n",
    "    # Quick guard\n",
    "    if (XShift == 0 and YShift == 0):\n",
    "        return Image\n",
    "\n",
    "    M = np.float32([\n",
    "        [1, 0, XShift],\n",
    "        [0, 1, YShift]\n",
    "    ])\n",
    "\n",
    "    shifted = cv2.warpAffine(Image, M, (Image.shape[1], Image.shape[0]))\n",
    "    shifted_image = shifted\n",
    "\n",
    "    # Shift Down\n",
    "    if (YShift > 0):\n",
    "        shifted_image = shifted_image[YShift:]\n",
    "        shifted_image = np.pad(shifted_image, ((YShift, 0), (0, 0)), 'edge')  # Pad Up\n",
    "\n",
    "    # Shift Up\n",
    "    if (YShift < 0):\n",
    "        shifted_image = shifted_image[:shifted.shape[0] - abs(YShift)]\n",
    "        shifted_image = np.pad(shifted_image, ((0, abs(YShift)), (0, 0)), 'edge')  # Pad Down\n",
    "\n",
    "    # Shift Left\n",
    "    if (XShift > 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(0, XShift), 1)\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (XShift, 0)), 'edge')  # Pad Left\n",
    "\n",
    "    if (XShift < 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(shifted.shape[1] - abs(XShift), shifted.shape[1]), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (0, abs(XShift))), 'edge');  # Pad Right\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "# sum of absolute differences (SAD) metric alignment, quick n dirty\n",
    "def SAD(A, B):\n",
    "    cutA = A.ravel();\n",
    "    cutB = B.ravel();\n",
    "    MAE = np.sum(np.abs(np.subtract(cutA, cutB, dtype=np.float64))) / cutA.shape[0]\n",
    "    return MAE\n",
    "\n",
    "# We use a Tree Search Algorithm to find possible alignment\n",
    "# Let Image_1 be the orginal\n",
    "# Let Image_2 be the aligned\n",
    "# Displacement object is our nodes, [x,y]\n",
    "# Assumption, there is always a better alignment up, down, left, and right if its not the same image\n",
    "def alignment_MAE(Image_1, Image_2, depth_cap):\n",
    "    iterative_cap = 0\n",
    "    Best_SAD = SAD(Image_1, Image_2)\n",
    "    Best_Displacement = [0, 0]\n",
    "    q = []\n",
    "    visited_states = [[0, 0]]  # Add (0,0) displacement\n",
    "    q.append(Best_Displacement)  # Append (0,0) displacement\n",
    "\n",
    "    while (iterative_cap != depth_cap and q):\n",
    "        curr_state = q.pop(0);\n",
    "        x = curr_state[0];\n",
    "        y = curr_state[1];\n",
    "\n",
    "        iterative_cap += 1;\n",
    "\n",
    "        movement_arr = [\n",
    "            [x, y - 1],  # Up\n",
    "            [x, y + 1],  # Down\n",
    "            [x + 1, y],  # Left\n",
    "            [x - 1, y],  # Right\n",
    "            [x - 1, y - 1],  # Diagonal\n",
    "            [x + 1, y + 1],  # Diagonal\n",
    "            [x + 1, y - 1],  # Diagonal\n",
    "            [x - 1, y + 1],  # Diagonal\n",
    "        ]\n",
    "\n",
    "        for move in movement_arr:\n",
    "            if (move not in visited_states):\n",
    "                visited_states.append(move)  # Marked as Visited\n",
    "\n",
    "                # Perform shift and calculate\n",
    "                new_image = ShiftedImage_2D(Image_2, move[0], move[1])\n",
    "                cand_SAD = SAD(Image_1, new_image)\n",
    "\n",
    "                if (cand_SAD < Best_SAD):\n",
    "                    Best_SAD = cand_SAD\n",
    "                    Best_Displacement = move\n",
    "\n",
    "                    q.append(move)\n",
    "\n",
    "                # This means we cannot find a better move.\n",
    "\n",
    "    return Best_Displacement, Best_SAD\n",
    "\n",
    "# Vec4f is (x1, y1, x2, y2)\n",
    "def y_shift_emphasis(image, block_threshold, MAE_shift, plot_debug=False):\n",
    "    output_img = image\n",
    "\n",
    "    # Need to turn into uint8 for Straight Line Detection\n",
    "    img = np.uint8(image)\n",
    "    lsd = cv2.createLineSegmentDetector(0)\n",
    "    lines_contour = lsd.detect(img)[0]\n",
    "\n",
    "    if plot_debug:\n",
    "        drawn_img = lsd.drawSegments(img, lines_contour);\n",
    "        plt.imshow(drawn_img, cmap='gray')\n",
    "        plt.title('Drawn Image')\n",
    "        plt.show()\n",
    "\n",
    "    horizontal_lines = {};\n",
    "    for x in lines_contour:\n",
    "        for y in x:\n",
    "            cand_gradient = abs(y[1] - y[3])\n",
    "            if (cand_gradient < 10):\n",
    "                horizontal_lines[cand_gradient] = y\n",
    "\n",
    "    horz = list(horizontal_lines.values())\n",
    "\n",
    "    top_y = np.min(horz);\n",
    "    bottom_y = np.max(horz);\n",
    "\n",
    "    return top_y, bottom_y\n",
    "\n",
    "def remove_stage_jitter_MAE(input_images, iteration_depth, plot_debug=False):\n",
    "    # Add Scores path just for curiosity\n",
    "    scores = []\n",
    "    result = []\n",
    "\n",
    "    # # Create Output folder\n",
    "    # if (not os.path.exists(output_path)):\n",
    "    #     os.makedirs(output_path);\n",
    "\n",
    "    # # Get training image files list:\n",
    "    # image_name_arr = glob.glob(os.path.join(source_path, \"*.png\")) + glob.glob(os.path.join(source_path, \"*.tif\"));\n",
    "    # image_name_arr_sorted = sorted(image_name_arr, key = lambda x:x[48:57]);\n",
    "\n",
    "    # base_image = os.path.basename(image_name_arr_sorted[0]);\n",
    "    # base = cv2.imread(os.path.join(source_path, base_image), cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "    base = input_images[0]\n",
    "\n",
    "    if base.ndim == 3:\n",
    "        base = base[:, :, 0]  # Reduce to the 2D\n",
    "\n",
    "    base_top, base_bottom = y_shift_emphasis(base, 15, 0)\n",
    "    iteration = 0\n",
    "\n",
    "    for img in input_images[1:]:\n",
    "        iteration += 1\n",
    "        template_image = img\n",
    "\n",
    "        if template_image.ndim == 3:\n",
    "            template_image = template_image[:, :, 0]  # Reduce to the 2D\n",
    "\n",
    "        template_top, template_bottom = y_shift_emphasis(template_image, 15, 0)\n",
    "\n",
    "        displacement, score = alignment_MAE(base, template_image, iteration_depth)\n",
    "        scores.append(score)\n",
    "        shifted_image = ShiftedImage_2D(template_image, displacement[0], int(np.mean(\n",
    "            [(base_top - template_top), (base_bottom - template_bottom)])))  # X,Y\n",
    "\n",
    "        # For my purposes\n",
    "        background = Image.fromarray(np.uint8(base))\n",
    "        overlay = Image.fromarray(np.uint8(shifted_image))\n",
    "        new_img = Image.blend(background, overlay, 0.5)\n",
    "\n",
    "        if plot_debug:\n",
    "            print(\"Overlay to show frame jitter\")\n",
    "            print(\"Overlay for image\", iteration)\n",
    "            plt.imshow(new_img, cmap='gray')\n",
    "            plt.title('New Image')\n",
    "            # plt.imshow(shifted_image, cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "        # Write the new image in target folder\n",
    "        shifted_image = exposure.rescale_intensity(shifted_image)  # Get rid of low exposure\n",
    "        result.append(shifted_image)\n",
    "\n",
    "    print(\"Scores:\", scores)\n",
    "\n",
    "    return result, scores"
   ],
   "id": "9b1e08a7a694991",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Load images\n",
    "import nd2\n",
    "\n",
    "test_dataset = nd2.imread(\n",
    "    '/Users/hiram/Documents/EVERYTHING/20-29 Research/22 OliveiraLab/22.12 ND2 analyzer/nd2-analyzer/SR_1_5_2h_Pre-C_3h_IPTG_After10h_05_MC.nd2',\n",
    "    dask=True)\n",
    "test_pos_over_time = test_dataset[:, 0, 0].compute()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(test_pos_over_time[0], cmap='gray')",
   "id": "ea061ed00001f69f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Normalization\n",
    "norm = cv2.normalize(test_pos_over_time, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "plt.imshow(norm[0], cmap='gray')\n",
    "plt.show()\n",
    "print('putaaa')\n",
    "# frames: (N,H,W) uint8\n",
    "frames = ((norm / 65535) * 255).astype(np.uint8)\n",
    "frames_rgb = np.stack([frames] * 3, axis=-1)  # (N,H,W,3)\n",
    "aligned, scores = remove_stage_jitter_MAE(frames, 1000)"
   ],
   "id": "5fd48d53217bfb14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save both timelapses and evaluate\n",
    "save_video(\"original.mp4\", frames)\n",
    "save_video(\"registered.mp4\", np.array(aligned))"
   ],
   "id": "697968f7105b8512",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Register with skimage (not good)",
   "id": "b283c8a4fb283ff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "\n",
    "def register_timestack(images):\n",
    "    registered = [images[0]]  # First frame as reference\n",
    "    shifts = [(0, 0)]\n",
    "\n",
    "    for i in range(1, len(images)):\n",
    "        shift, error, phase_diff = phase_cross_correlation(\n",
    "            images[0], images[i],\n",
    "            upsample_factor=100  # for sub-pixel precision\n",
    "        )\n",
    "        registered.append(np.roll(images[i], shift.astype(int), axis=(0, 1)))\n",
    "        shifts.append(shift)\n",
    "\n",
    "    return registered, shifts"
   ],
   "id": "c3ef32aa563a8141",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# frames: a NumPy array of shape (N, H, W) or (N, H, W, 3)\n",
    "def show_frames_matplotlib(frames, delay=0.1):\n",
    "    plt.ion()  # interactive mode on\n",
    "    fig, ax = plt.subplots()\n",
    "    for frame in frames:\n",
    "        ax.clear()\n",
    "        if frame.ndim == 2:\n",
    "            ax.imshow(frame, cmap='gray', vmin=0, vmax=255)\n",
    "        else:\n",
    "            ax.imshow(frame)\n",
    "        ax.axis('off')\n",
    "        display(fig)\n",
    "        plt.pause(delay)\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ],
   "id": "b73b0baffe08d058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Normalization\n",
    "norm = cv2.normalize(test_pos_over_time.compute(), None, 0, 65535, cv2.NORM_MINMAX)\n",
    "# plt.imshow(norm[0], cmap='gray')\n",
    "# frames: (N,H,W) uint8\n",
    "frames = ((norm / 65535) * 255).astype(np.uint8)\n",
    "frames_rgb = np.stack([frames] * 3, axis=-1)  # (N,H,W,3)\n",
    "\n",
    "# frames_rgb: (N, H, W, 3) uint8 in RGB\n",
    "h, w = frames_rgb.shape[1], frames_rgb.shape[2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"timelapse.mp4\", fourcc, 15.0, (w, h), isColor=True)\n",
    "\n",
    "for fr in frames_rgb:\n",
    "    fr_bgr = cv2.cvtColor(fr, cv2.COLOR_RGB2BGR)\n",
    "    out.write(fr_bgr)\n",
    "\n",
    "out.release()\n",
    "print(\"Saved timelapse.mp4\")\n"
   ],
   "id": "3f6a464d59ff5813",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "frames_rgb.shape",
   "id": "20cf262db1d0a7ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Do the registration\n",
    "registered, shifts = register_timestack(frames)"
   ],
   "id": "e555ed0110b7d5c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# # frames: (N,H,W) uint8\n",
    "# frames = ((test_pos_over_time / 65535) * 255).compute().astype(np.uint8)\n",
    "# frames_rgb = np.stack([frames]*3, axis=-1)  # (N,H,W,3)\n",
    "\n",
    "# frames_rgb: (N, H, W, 3) uint8 in RGB\n",
    "h, w = frames.shape[1], frames.shape[2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"registered.mp4\", fourcc, 15.0, (w, h), isColor=True)\n",
    "\n",
    "for fr in registered:\n",
    "    fr_bgr = cv2.cvtColor(fr, cv2.COLOR_GRAY2BGR)\n",
    "    out.write(fr_bgr)\n",
    "\n",
    "out.release()\n",
    "print(\"Saved timelapse.mp4\")\n"
   ],
   "id": "a300c0117337d397",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "22ee22eeaf90f8ba",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
