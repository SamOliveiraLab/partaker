{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ad300-cf3a-4430-a7b1-520521a5f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import omnipose\n",
    "\n",
    "# set up plotting defaults\n",
    "omnipose.plot.setup()\n",
    "\n",
    "# This checks to see if you have set up your GPU properly.\n",
    "# CPU performance is a lot slower, but not a problem if you \n",
    "# are only processing a few images.\n",
    "from omnipose.gpu import use_gpu\n",
    "use_GPU = use_gpu()\n",
    "\n",
    "# for plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nd2_file = '/Users/hiram/Documents/EVERYTHING/20-29 Research/22 OliveiraLab/22.12 ND2 analyzer/nd2-analyzer/SR_1_5_2h_Pre-C_3h_IPTG_After10h_05_MC.nd2'\n",
    "import nd2\n",
    "\n",
    "# Load the ND2 file (without closing it immediately)\n",
    "with nd2.ND2File(nd2_file) as reader:\n",
    "    images = reader.to_dask(nd2_file)\n",
    "    test_img = images[0, 0, 0].compute()\n",
    "\n",
    "# Check the total number of frames\n",
    "print(f\"Total frames: {len(images)}\")\n",
    "\n",
    "# Display the first frame\n",
    "plt.imshow(test_img, cmap=\"gray\")\n",
    "plt.title(\"First Frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cellpose_omni import models\n",
    "\n",
    "model_name = 'bact_phase_omni'\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "chans = [0,0] #this means segment based on first channel, no second channel \n",
    "\n",
    "# n = [-1] # make a list of integers to select which images you want to segment\n",
    "# n = range(nimg) # or just segment them all \n",
    "n = [0]\n",
    "\n",
    "# define parameters\n",
    "params = {'channels':chans, # always define this with the model\n",
    "          'rescale': None, # upscale or downscale your images, None = no rescaling \n",
    "          'mask_threshold': -2, # erode or dilate masks with higher or lower values between -5 and 5 \n",
    "          'flow_threshold': 0, # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "          'transparency': True, # transparency in flow output\n",
    "          'omni': True, # we can turn off Omnipose mask reconstruction, not advised \n",
    "          'cluster': True, # use DBSCAN clustering\n",
    "          'resample': True, # whether or not to run dynamics on rescaled grid or original grid \n",
    "          'verbose': False, # turn on if you want to see more output \n",
    "          'tile': False, # average the outputs from flipped (augmented) images; slower, usually not needed \n",
    "          'niter': None, # default None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation \n",
    "          'augment': False, # Can optionally rotate the image and average network outputs, usually not needed \n",
    "          # 'affinity_seg': True, # new feature, stay tuned...\n",
    "         }\n",
    "\n",
    "imgs = [test_img]\n",
    "\n",
    "tic = time.time() \n",
    "masks, flows, styles = model.eval([imgs[i] for i in n],**params)\n",
    "\n",
    "net_time = time.time() - tic\n",
    "\n",
    "print('total segmentation time: {}s'.format(net_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "maski = masks[0]\n",
    "maski.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import plot\n",
    "import omnipose\n",
    "\n",
    "for idx,i in enumerate(n):\n",
    "\n",
    "    maski = masks[idx] # get masks\n",
    "    bdi = flows[idx][-1] # get boundaries\n",
    "    flowi = flows[idx][0] # get RGB flows \n",
    "\n",
    "    # set up the output figure to better match the resolution of the images \n",
    "    f = 15\n",
    "    szX = maski.shape[-1]/mpl.rcParams['figure.dpi']*f\n",
    "    szY = maski.shape[-2]/mpl.rcParams['figure.dpi']*f\n",
    "    fig = plt.figure(figsize=(szY,szX*4), facecolor=[0]*4, frameon=False)\n",
    "    \n",
    "    plot.show_segmentation(fig, omnipose.utils.normalize99(imgs[i]), \n",
    "                           maski, flowi, bdi, channels=chans, omni=True,\n",
    "                           interpolation=None)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd959d0d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a796bf5",
   "metadata": {},
   "source": [
    "# Let's try doing it multichannel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de51145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba956272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import plot\n",
    "import omnipose\n",
    "\n",
    "for idx,i in enumerate(n):\n",
    "\n",
    "    maski = masks[idx] # get masks\n",
    "    bdi = flows[idx][-1] # get boundaries\n",
    "    flowi = flows[idx][0] # get RGB flows \n",
    "\n",
    "    # set up the output figure to better match the resolution of the images \n",
    "    f = 15\n",
    "    szX = maski.shape[-1]/mpl.rcParams['figure.dpi']*f\n",
    "    szY = maski.shape[-2]/mpl.rcParams['figure.dpi']*f\n",
    "    fig = plt.figure(figsize=(szY,szX*4), facecolor=[0]*4, frameon=False)\n",
    "    \n",
    "    plot.show_segmentation(fig, omnipose.utils.normalize99(imgs[i]), \n",
    "                           maski, flowi, bdi, channels=chans, omni=True,\n",
    "                           interpolation=None)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
